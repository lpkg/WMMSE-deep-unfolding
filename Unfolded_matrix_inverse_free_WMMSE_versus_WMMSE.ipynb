{"cells":[{"cell_type":"markdown","source":["# **Unfolded matrix-inverse-free WMMSE versus WMMSE**\n","\n","The WMMSE algorithm is implemented as described in the paper \"An Iteratively Weighted MMSE Approach to Distributed Sum-Utility Maximization for a MIMO Interfering Broadcast Channel\", by Q. Shi et al.\n","\n","Note:\n","\n","Functions and variables with \"_nn\" (i.e. neural network) in the name refer to the deep unfolded WMMSE algorithm.\n","\n","In the code we use the term precoder to indicate the beamformer"],"metadata":{"id":"V5_UiC0xiXBq"}},{"cell_type":"markdown","source":["##**Import libraries and set variables**"],"metadata":{"id":"sXrEm_5ilRH7"}},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4794,"status":"ok","timestamp":1652816088551,"user":{"displayName":"Lissy Pellaco","userId":"16790785239086063280"},"user_tz":-120},"id":"byUNI2UtMmQd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9ab57cc3-ddcb-45ba-cb24-1249fff8a52c"},"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow 1.x selected.\n"]}],"source":["%tensorflow_version 1.x\n","# Import libraries\n","import tensorflow as tf # tensorflow_version 1.x is needed\n","from tensorflow.python.framework import ops\n","import numpy as np\n","import copy\n","from copy import deepcopy\n","import time\n","import matplotlib.pyplot as plt\n","\n","# Set variables\n","nr_of_users = 4\n","nr_of_BS_antennas = 8\n","nr_of_UE_antennas = 2\n","nr_of_data_streams = 2\n","total_power = 10 # power constraint in the weighted sum rate maximization problem \n","noise_power = 1\n","nr_of_iterations = 4\n","scale_V_every_iteration = True # used to normalize V at every iteration such that the power constraint is met with equality\n","\n","# For the WMMSE\n","epsilon = 0.0001 # used to end the iterations of the WMMSE algorithm in Shi et al. when the number of iterations is not fixed (note that the stopping criterion has precendence over the fixed number of iterations)\n","power_tolerance = 0.0001 # used to end the bisection search in the WMMSE algorithm in Shi et al.\n","nr_of_iterations_WMMSE = nr_of_iterations # for WMMSE algorithm in Shi et al.\n","user_weights_WMMSE = np.ones((nr_of_users),)\n","\n","# For the matrxi-inverse-free WMMSE\n","nr_of_batches_training = 10000#  used for training\n","nr_of_batches_test = 1000 # used for testing\n","nr_of_samples_per_batch = 100\n","batch_size = nr_of_samples_per_batch\n","\n","nr_of_iterations_nn = nr_of_iterations  # for the deep unfolded WMMSE in our paper\n"]},{"cell_type":"markdown","source":["#**Function to run the WMMSE algorithm described in the paper by Shi et al**"],"metadata":{"id":"yKpOr-KDo2mO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"F8esMB3zbv41"},"outputs":[],"source":["def compute_sinr_MIMO(channel, precoder, noise_power, user_id):\n","  result = 0\n","  nr_of_users = np.size(channel,0)\n","  nr_of_UE_antennas = np.size(channel,1)\n","  inter_user_interference = np.zeros((nr_of_UE_antennas,nr_of_UE_antennas)) + 1j*np.zeros((nr_of_UE_antennas,nr_of_UE_antennas))\n","\n","  numerator = np.matmul(np.matmul(np.matmul(channel[user_id,:,:],precoder[user_id,:,:]), np.transpose(np.conj(precoder[user_id,:,:]))), np.transpose(np.conj(channel[user_id,:,:])))\n","\n","  for user_index in range(nr_of_users):\n","    if user_index != user_id:\n","      inter_user_interference = inter_user_interference + np.matmul(np.matmul(np.matmul(channel[user_id,:,:],precoder[user_index,:,:]), \\\n","                                                                              np.transpose(np.conj(precoder[user_index,:,:]))), np.transpose(np.conj(channel[user_id,:,:])))\n","\n","  denominator = noise_power*np.eye(nr_of_UE_antennas,nr_of_UE_antennas)+ inter_user_interference\n","\n","  result = np.matmul(numerator, np.linalg.inv(denominator))\n","\n","  return result\n","\n","\n","def compute_weighted_sum_rate_MIMO(user_weights, channel, precoder, noise_power):\n","  result = 0\n","  nr_of_users = np.size(channel,0)\n","  nr_of_UE_antennas = np.size(channel,1)\n","  \n","  for user_index in range(nr_of_users):\n","    user_sinr = compute_sinr_MIMO(channel, precoder, noise_power, user_index)\n","    result = result + user_weights[user_index]*np.log(np.linalg.det(np.eye(nr_of_UE_antennas,nr_of_UE_antennas) + user_sinr))\n","  \n","  result = np.real(result)\n","\n","  return result\n","\n","\n","def run_WMMSE_MIMO_more_streams(epsilon, channel, initial_transmitter_precoder_WMMSE, total_power, noise_power, user_weights, max_nr_of_iterations, log = False):\n","# initialization\n","  mse_weights = np.zeros((nr_of_users,nr_of_data_streams,nr_of_data_streams)) + 1j*np.zeros((nr_of_users,nr_of_data_streams,nr_of_data_streams)) \n","  receiver_precoder = np.zeros((nr_of_users,nr_of_UE_antennas,nr_of_data_streams)) +1j*np.zeros((nr_of_users,nr_of_UE_antennas,nr_of_data_streams))\n","  transmitter_precoder = np.zeros((nr_of_users,nr_of_BS_antennas,nr_of_data_streams)) +1j*np.zeros((nr_of_users,nr_of_BS_antennas,nr_of_data_streams))\n","  new_transmitter_precoder = np.zeros((nr_of_users,nr_of_BS_antennas,nr_of_data_streams)) +1j*np.zeros((nr_of_users,nr_of_BS_antennas,nr_of_data_streams))\n","  new_receiver_precoder = np.zeros((nr_of_users,nr_of_UE_antennas,nr_of_data_streams)) +1j*np.zeros((nr_of_users,nr_of_UE_antennas,nr_of_data_streams))\n","  WSR_E = [0]\n","  WSR = []\n","\n","  for user_index in range(nr_of_users):\n","    receiver_precoder[user_index, :,:] = np.zeros((nr_of_UE_antennas,nr_of_data_streams))\n","    transmitter_precoder[user_index, :,:] = np.random.normal(size = (nr_of_BS_antennas,nr_of_data_streams))\n","\n","  power = (np.linalg.norm(transmitter_precoder))**2\n","  transmitter_precoder = initial_transmitter_precoder_WMMSE\n","  mse_weigths_old = mse_weights\n","\n","  nr_of_iteration_counter = 1 # to keep track of the number of iteration of the WMMSE\n","  break_condition = 2*epsilon\n","\n","  while break_condition >= epsilon and nr_of_iteration_counter<=max_nr_of_iterations:\n","\n","    nr_of_iteration_counter = nr_of_iteration_counter + 1\n","\n","    ###################################\n","    # optimize receiver precoder\n","    for user_index in range(nr_of_users):\n","      user_interference = np.zeros((nr_of_UE_antennas,nr_of_UE_antennas)) +1j*np.zeros((nr_of_UE_antennas,nr_of_UE_antennas))\n","      for user_index2 in range(nr_of_users):\n","        user_interference = user_interference + np.matmul(channel[user_index,:,:],np.matmul(transmitter_precoder[user_index2,:,:],\\\n","                                                                                            np.matmul(np.transpose(np.conj(transmitter_precoder[user_index2,:,:])),np.transpose(np.conj(channel[user_index,:,:])) ) ) )\n","      \n","      new_receiver_precoder[user_index,:,:] = np.matmul(np.linalg.inv(np.eye(nr_of_UE_antennas,nr_of_UE_antennas)*noise_power + user_interference) , \\\n","                                                    np.matmul(channel[user_index,:,:],transmitter_precoder[user_index,:,:]))\n","\n","    ####################################\n","    # optimize mse weights\n","    for user_index in range(nr_of_users):\n","      mse_weights[user_index,:,:] = np.linalg.inv(np.eye(nr_of_data_streams,nr_of_data_streams) - np.matmul(np.matmul(np.transpose(np.conj(new_receiver_precoder[user_index,:,:])),channel[user_index,:,:]),transmitter_precoder[user_index,:,:]))\n","    \n","    ####################################\n","    # optimize transmitter precoder\n","    A = np.zeros((nr_of_BS_antennas,nr_of_BS_antennas))+1j*np.zeros((nr_of_BS_antennas,nr_of_BS_antennas))\n"," \n","    for user_index in range(nr_of_users):\n","      A = A + user_weights[user_index]*np.matmul(np.matmul(np.matmul(np.matmul(np.transpose(np.conj(channel[user_index,:,:])),new_receiver_precoder[user_index,:,:]),\\\n","                                            mse_weights[user_index,:,:]),np.transpose(np.conj(new_receiver_precoder[user_index,:,:]))), channel[user_index,:,:])\n","      \n","    Sigma_diag_elements_true, U = np.linalg.eigh(A)\n","    Sigma_diag_elements = copy.deepcopy(np.real(Sigma_diag_elements_true))\n","    Lambda = np.zeros((nr_of_BS_antennas,nr_of_BS_antennas)) + 1j*np.zeros((nr_of_BS_antennas,nr_of_BS_antennas))\n","    \n","    for user_index in range(nr_of_users):\n","      Lambda = Lambda + ((user_weights[user_index])**2)* np.matmul(np.matmul(np.matmul(np.matmul(np.matmul(\\\n","                                                                np.transpose(np.conj(channel[user_index,:,:])),\\\n","                                                       new_receiver_precoder[user_index,:,:]),mse_weights[user_index,:,:]), np.transpose(np.conj(mse_weights[user_index,:,:]))),\\\n","                                                       np.transpose(np.conj(new_receiver_precoder[user_index,:,:]))),channel[user_index,:,:])\n","\n","    Phi = np.matmul(np.matmul(np.conj(np.transpose(U)),Lambda),U)\n","    Phi_diag_elements_true = np.diag(Phi)\n","    Phi_diag_elements = copy.deepcopy(Phi_diag_elements_true)\n","    Phi_diag_elements = np.real(Phi_diag_elements)\n","\n","    for i in range(len(Phi_diag_elements)):\n","      if Phi_diag_elements[i]<np.finfo(float).eps:\n","        Phi_diag_elements[i] = np.finfo(float).eps\n","      if (Sigma_diag_elements[i])<np.finfo(float).eps:\n","        Sigma_diag_elements[i] = 0\n","\n","    # Check if mu = 0 is a solution (eq.s (15) and (16) of in the paper of Shi et al.)\n","    power = 0 # the power of transmitter precoder (i.e. sum of the squared norm)\n","    for user_index in range(nr_of_users):\n","      if np.linalg.det(A) != 0:\n","        temp = np.matmul(np.linalg.inv(A), np.matmul(np.matmul(np.transpose(np.conj(channel[user_index,:,:])), new_receiver_precoder[user_index,:,:]),mse_weights[user_index,:,:]))\n","        power = power + (np.linalg.norm(temp))**2\n","\n","    # If mu = 0 is a solution, then mu_star = 0\n","    if np.linalg.det(A) != 0 and power <= total_power:\n","      mu_star = 0\n","    # If mu = 0 is not a solution then we search for the \"optimal\" mu by bisection\n","    else:\n","      power_distance = [] # list to store the distance from total_power in the bisection algorithm \n","      mu_low = np.sqrt(1/total_power*np.sum(Phi_diag_elements))\n","      mu_high = 0\n","      low_point = compute_P(Phi_diag_elements, Sigma_diag_elements, mu_low)\n","      high_point = compute_P(Phi_diag_elements, Sigma_diag_elements, mu_high)\n","\n","      obtained_power = total_power + 2*power_tolerance # initialization of the obtained power such that we enter the while \n","\n","      # Bisection search\n","      while np.absolute(total_power - obtained_power) > power_tolerance:\n","        mu_new = (mu_high + mu_low)/2\n","        obtained_power = compute_P(Phi_diag_elements, Sigma_diag_elements, mu_new) # eq. (18) in the paper of Shi et al.\n","        power_distance.append(np.absolute(total_power - obtained_power))\n","        if obtained_power > total_power:\n","          mu_high = mu_new\n","        if obtained_power < total_power:\n","          mu_low = mu_new\n","      mu_star = mu_new\n","\n","      if log == True:\n","        print(\"first value:\", power_distance[0])\n","        plt.title(\"Distance from the target value in bisection (it should decrease)\")\n","        plt.plot(power_distance)\n","        plt.show()\n","\n","    for user_index in range(nr_of_users):\n","        new_transmitter_precoder[user_index,:,:] = user_weights[user_index]*np.matmul(np.matmul(np.matmul(np.linalg.inv(A  + mu_star*np.eye(nr_of_BS_antennas,nr_of_BS_antennas)), \\\n","                                                             np.transpose(np.conj(channel[user_index,:,:]))),new_receiver_precoder[user_index,:,:]),mse_weights[user_index,:,:])\n","\n","    transmitter_precoder = deepcopy(new_transmitter_precoder)\n","    receiver_precoder = deepcopy(new_receiver_precoder)\n","\n","    WSR_E.append( np.real(np.sum(np.multiply(np.log(np.squeeze(np.linalg.det(np.real(mse_weights)))),user_weights))))\n","    mse_weights_old = mse_weights\n","    WSR.append(compute_weighted_sum_rate_MIMO(user_weights, channel, transmitter_precoder, noise_power))\n","    break_condition = np.absolute(WSR_E[-1] - WSR_E[-2])\n","\n","  if log == True:\n","    plt.title(\"Change of the WSR at each iteration of the WMMSE (it should increase)\")\n","    plt.plot(WSR,'bo')\n","    plt.show()\n","\n","  return transmitter_precoder, receiver_precoder, mse_weights, WSR[-1]\n","\n","\n","# Compute power for bisection search in the optimization of the transmitter precoder \n","# - eq. (18) in the paper by Shi et al.\n","def compute_P(Phi_diag_elements, Sigma_diag_elements, mu):\n","  nr_of_BS_antennas = Phi_diag_elements.size\n","  mu_array = mu*np.ones(Phi_diag_elements.size)\n","  result = np.divide(Phi_diag_elements,(Sigma_diag_elements + mu_array)**2)\n","  result = np.sum(result)\n","  return result\n","\n","\n","# Computes a channel realization and returns it in two formats, one for the WMMSE and one for the unfolded matrix-inverse-free WMMSE.\n","# It also returns the initialization value of the transmitter precoder and the receiver precoder, which are used as input in the computation graph of the unfolded matrix-inverse-free WMMSE.\n","def compute_channel(nr_of_BS_antennas, nr_of_users, total_power ):\n","  channel_nn = []\n","  initial_transmitter_precoder = []\n","  initial_transmitter_precoder_WMMSE = []\n","  initial_receiver_precoder = []\n","  channel_WMMSE = np.zeros((nr_of_users,nr_of_UE_antennas, nr_of_BS_antennas)) + 1j*np.zeros((nr_of_users, nr_of_UE_antennas,nr_of_BS_antennas))\n","\n","  transmitter_precoder_power = 0\n","\n","  VVh = 0\n","  nr_of_Schulz_iterations = 1\n","\n","  # If number of data streams is equal to one\n","  if nr_of_data_streams == 1:\n","\n","    for i in range(nr_of_users):\n","\n","        result_real = np.sqrt(0.5)*np.random.normal(size = (nr_of_UE_antennas,nr_of_BS_antennas))\n","        result_imag = np.sqrt(0.5)*np.random.normal(size = (nr_of_UE_antennas,nr_of_BS_antennas))\n","\n","        channel_WMMSE[i,:,:] = np.reshape(result_real,(nr_of_UE_antennas,nr_of_BS_antennas)) + 1j*np.reshape(result_imag, (nr_of_UE_antennas,nr_of_BS_antennas))\n","\n","        result_col_1 = np.vstack((result_real,result_imag))\n","        result_col_2 = np.vstack((-result_imag,result_real))\n","        result =  np.hstack((result_col_1, result_col_2))\n","        channel_nn.append(result)\n","\n","        ## transmitter precoder\n","        tp = np.reshape(np.sum(result_real,axis = 0),(nr_of_BS_antennas,1)) +1j*np.reshape(-1*np.sum(result_imag,axis = 0),(nr_of_BS_antennas,1))\n","        initial_transmitter_precoder_WMMSE.append(tp)\n","\n","        real_tp = np.real(tp)\n","        imag_tp = np.imag(tp)\n","        \n","        first_row_tp = np.concatenate((real_tp,-1*imag_tp), axis = 1) \n","        second_row_tp = np.concatenate((imag_tp,real_tp), axis = 1)\n","\n","        initial_transmitter_precoder.append(np.concatenate((first_row_tp,second_row_tp), axis = 0))\n","        transmitter_precoder_power = transmitter_precoder_power + np.linalg.norm(tp)**2\n","\n","        ## receiver precoder\n","        rp = np.reshape(np.sum(result_real,axis = 1),(nr_of_UE_antennas,1)) +1j*np.reshape(np.sum(result_imag,axis = 1),(nr_of_UE_antennas,1))\n","        real_rp = np.real(rp)\n","        imag_rp = np.imag(rp)\n","        \n","        first_row_rp = np.concatenate((real_rp,-1*imag_rp), axis = 1) \n","        second_row_rp = np.concatenate((imag_rp,real_rp), axis = 1)\n","\n","        initial_receiver_precoder.append(np.concatenate((first_row_rp,second_row_rp), axis = 0))\n","\n","    initial_transmitter_precoder = np.array(initial_transmitter_precoder)    \n","    initial_transmitter_precoder_WMMSE = np.array(initial_transmitter_precoder_WMMSE)\n","    \n","    initial_transmitter_precoder = np.sqrt(total_power)*initial_transmitter_precoder/np.sqrt(transmitter_precoder_power)\n","    initial_transmitter_precoder_WMMSE = np.sqrt(total_power)*initial_transmitter_precoder_WMMSE/np.sqrt(transmitter_precoder_power)\n","\n","  else:\n","    ## transmitter precoder\n","    for i in range(nr_of_users):\n","       \n","        result_real = np.sqrt(0.5)*np.random.normal(size = (nr_of_UE_antennas,nr_of_BS_antennas))\n","        result_imag = np.sqrt(0.5)*np.random.normal(size = (nr_of_UE_antennas,nr_of_BS_antennas))\n","\n","        temp = np.reshape(result_real,(nr_of_UE_antennas,nr_of_BS_antennas)) + 1j*np.reshape(result_imag, (nr_of_UE_antennas,nr_of_BS_antennas))\n","\n","        channel_WMMSE[i,:,:] = temp\n","\n","        result_col_1 = np.vstack((result_real,result_imag))\n","        result_col_2 = np.vstack((-result_imag,result_real))\n","        result =  np.hstack((result_col_1, result_col_2))\n","        channel_nn.append(result)\n","        channel_norm_by_row = np.linalg.norm(temp,axis = 1 )\n","        channel_row_index = (np.argsort(channel_norm_by_row))[-nr_of_data_streams:][::-1]\n","\n","        tp = np.transpose(np.conj(temp[channel_row_index,])) \n","        transmitter_precoder_power = transmitter_precoder_power + np.linalg.norm(tp)**2\n","        initial_transmitter_precoder_WMMSE.append(tp)\n","\n","        real_tp = np.real(tp)\n","        imag_tp = np.imag(tp)\n","        \n","        first_row_tp = np.concatenate((real_tp,-1*imag_tp), axis = 1) \n","        second_row_tp = np.concatenate((imag_tp,real_tp), axis = 1)\n","        initial_transmitter_precoder.append(np.concatenate((first_row_tp,second_row_tp), axis = 0))\n","\n","    initial_transmitter_precoder = np.array(initial_transmitter_precoder)    \n","    initial_transmitter_precoder_WMMSE = np.array(initial_transmitter_precoder_WMMSE)\n","\n","    initial_transmitter_precoder = np.sqrt(total_power)*initial_transmitter_precoder/np.sqrt(transmitter_precoder_power)\n","    initial_transmitter_precoder_WMMSE = np.sqrt(total_power)*initial_transmitter_precoder_WMMSE/np.sqrt(transmitter_precoder_power)\n","\n","    I = np.eye(nr_of_UE_antennas)\n","\n","    for i in range(nr_of_users):\n","      VVh = VVh + np.matmul(initial_transmitter_precoder_WMMSE[i,:,:], np.transpose(np.conj(initial_transmitter_precoder_WMMSE[i,:,:])))\n","    \n","    ## receiver precoder\n","    if nr_of_data_streams != nr_of_UE_antennas:\n","      # Initialize U as matched filtering\n","      for i in range(nr_of_users):\n","\n","        rp = np.matmul(channel_WMMSE[i,:,:],initial_transmitter_precoder_WMMSE[i,:,:])\n","        real_rp = np.real(rp)\n","        imag_rp = np.imag(rp)\n","  \n","        first_row_rp = np.concatenate((real_rp,-1*imag_rp), axis = 1) \n","        second_row_rp = np.concatenate((imag_rp,real_rp), axis = 1)\n","\n","        initial_receiver_precoder.append(np.concatenate((first_row_rp,second_row_rp), axis = 0))\n","\n","    if nr_of_data_streams == nr_of_UE_antennas:\n","    # Initialize U as scaled identity matrix\n","    \n","      for i in range(nr_of_users):\n","\n","        scaling = (np.trace(np.matmul(channel_WMMSE[i,:,:],initial_transmitter_precoder_WMMSE[i,:,:])))/(noise_power*nr_of_UE_antennas + np.trace(np.matmul(np.matmul(channel_WMMSE[i,:,:],VVh),np.transpose(np.conj(channel_WMMSE[i,:,:])))))\n","\n","        rp = np.eye(nr_of_UE_antennas)*np.real(scaling)\n","\n","        real_rp = np.real(rp)\n","        imag_rp = np.imag(rp)\n","        \n","        first_row_rp = np.concatenate((real_rp,-1*imag_rp), axis = 1) \n","        second_row_rp = np.concatenate((imag_rp,real_rp), axis = 1)\n","\n","        initial_receiver_precoder.append(np.concatenate((first_row_rp,second_row_rp), axis = 0))\n","\n","  return channel_nn, initial_transmitter_precoder, initial_receiver_precoder, channel_WMMSE, initial_transmitter_precoder_WMMSE\n","\n","\n","def compute_WSR_neural_network(H, V, noise_power,user_weights,batch_size):  \n","\n","  VVh_single_user = tf.matmul(V,tf.transpose(V, perm = [0,1,3,2]))\n","  VVh = tf.expand_dims(tf.reduce_sum(VVh_single_user, axis = 1), axis = 1)\n","  VVh_other_users = VVh - VVh_single_user\n","\n","  I = tf.eye(2*nr_of_UE_antennas, 2*nr_of_UE_antennas, batch_shape = [batch_size, nr_of_users],dtype=tf.dtypes.float64) \n","\n","  HVVhHh = tf.matmul(tf.matmul(H,VVh_other_users), tf.transpose(H, perm = [0,1,3,2])) \n","  HVVhHh_single_user = tf.matmul(tf.matmul(H,VVh_single_user),tf.transpose(H, perm = [0,1,3,2]))\n","\n","  rate_per_user = tf.multiply(user_weights,0.5*(tf.log(tf.linalg.det(tf.matmul(HVVhHh_single_user,tf.linalg.inv(HVVhHh + noise_power*I)) + I))))\n","\n","  return tf.reduce_sum(tf.reduce_sum(rate_per_user,axis = 1),axis = 0)/batch_size\n"]},{"cell_type":"markdown","source":["# **Define the gradient descent for the updates of U and V and Schulz iterations for the update of W**"],"metadata":{"id":"ap72luWoqEvH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Wx0z2C12xmL"},"outputs":[],"source":["\n","def Schulz(W,E,I):\n","\n","  W_temp = tf.matmul(W,(2*I - tf.matmul(E,W)))\n","\n","  return (W_temp + tf.transpose(W_temp,perm=[0,1,3,2]))*0.5\n","\n","\n","# Builds one Nesterov-accelerated GD iteration of the V update in the unfolded matrix-inverse-free WMMSE and computes the optimal step size\n","def GD_step_V_line_search_more_streams_Nesterov( init,init_momentum1, init_momentum2, name, mse_weights, user_weights, U,H, V,V_past, A, total_power):\n","\n","  with tf.variable_scope(name): \n","\n","    epsilon_numerical_instability = 10**(-9)\n","    step_size_factor_temp =  tf.Variable(tf.constant(init, dtype=tf.float64), name=name, dtype=tf.float64)\n","    step_size_factor = 2*tf.math.sigmoid(step_size_factor_temp)\n","    momentum1 =  tf.Variable(tf.constant(init_momentum1, dtype = tf.float64), name = \"momentum_1\", dtype = tf.float64, trainable = True)\n","    momentum2 =  tf.Variable(tf.constant(init_momentum2, dtype = tf.float64), name = \"momentum_2\", dtype = tf.float64, trainable = True)\n","    I = tf.eye(nr_of_BS_antennas,batch_shape = [batch_size],dtype=tf.dtypes.float64) \n","\n","    V_a = V + momentum1*(V - V_past)\n","    V_b = V + momentum2*(V - V_past)\n","    \n","    Uh = tf.transpose(U,perm=[0,1,3,2])\n","    WUhU = tf.matmul(mse_weights,tf.matmul(Uh,U)) \n","\n","    real_sum_trace_WUhU = tf.multiply(tf.expand_dims(tf.expand_dims(tf.reduce_sum(tf.trace(WUhU)*0.5,axis =-1),axis = -1),axis = -1),I) \n","    imag_sum_trace_WUhU = tf.multiply(tf.expand_dims(tf.expand_dims(tf.reduce_sum(tf.trace(WUhU[:,:,-nr_of_data_streams:,:nr_of_data_streams]),axis =-1),axis = -1),axis = -1),I) \n","\n","    real_sum_trace_WUhU_exp = tf.tile(tf.expand_dims(real_sum_trace_WUhU,axis = 1),(1,nr_of_users,1,1)) \n","    imag_sum_trace_WUhU_exp = tf.tile(tf.expand_dims(imag_sum_trace_WUhU,axis = 1),(1,nr_of_users,1,1)) \n","    \n","    sum_trace_WUhU_first_row = tf.concat((real_sum_trace_WUhU_exp,-1*imag_sum_trace_WUhU_exp),axis = 3)\n","    sum_trace_WUhU_second_row = tf.concat((imag_sum_trace_WUhU_exp,real_sum_trace_WUhU_exp),axis = 3)\n","    sum_trace_WUhU = tf.concat((sum_trace_WUhU_first_row,sum_trace_WUhU_second_row),axis = 2) \n","\n","    gradient = 2*tf.matmul(A,V_b)-2*tf.multiply(user_weights,tf.matmul(tf.matmul(tf.transpose(H, perm = [0,1,3,2]),U),mse_weights)) + 2*noise_power*(1/total_power)*tf.matmul(sum_trace_WUhU,V_b)\n","\n","    ######################################\n","    # FIND OPTIMAL STEP SIZE##############\n","    ######################################\n","\n","    ######################################\n","    ## NUMERATOR\n","    ######################################\n","    \n","\n","    # FIRST AND SECOND TERMS NUMERATOR\n","    Vh = tf.transpose(V_a, perm = [0,1,3,2])\n","    GVh = tf.matmul(gradient,Vh) \n","    VGh = tf.transpose(GVh,perm = [0,1,3,2])\n","    HG = tf.matmul(H,gradient)\n","\n","    HhU = tf.matmul(tf.transpose(H, perm = [0,1,3,2]),U)\n","\n","    UhH = tf.transpose(HhU, perm = [0,1,3,2])\n","\n","    first_term_numerator =  tf.reduce_sum(tf.multiply(0.5*tf.trace(tf.matmul(mse_weights,tf.matmul(tf.matmul(UhH,GVh),HhU))), user_weights[:,:,0,0]), axis = 1) \n","    second_term_numerator =  tf.reduce_sum(tf.multiply(0.5*tf.trace(tf.matmul(mse_weights,tf.matmul(tf.matmul(UhH,VGh),HhU))), user_weights[:,:,0,0]), axis = 1) \n","    \n","\n","    # THIRD AND FOURTH TERMS NUMERATOR\n","    Gh = tf.transpose(gradient, perm = [0,1,3,2])\n","    third_term_numerator = tf.reduce_sum(tf.multiply(0.5*tf.trace(tf.matmul(mse_weights,tf.matmul(Gh,HhU))),user_weights[:,:,0,0]), axis =1) \n","    fourth_term_numerator = tf.reduce_sum(tf.multiply(0.5*tf.trace(tf.matmul(mse_weights,tf.matmul(Uh,HG))),user_weights[:,:,0,0]), axis =1) \n","  \n","\n","    # FIFTH AND SIXTH TERMS NUMERATOR\n","    GVh_all_users  = tf.reduce_sum(GVh, axis = 1) \n","    GVh_other_users = tf.tile(tf.expand_dims(GVh_all_users, axis = 1),(1,nr_of_users,1,1)) - GVh \n","    VGh_other_users = tf.transpose(GVh_other_users, perm = [0,1,3,2])\n","    \n","    fifth_term_numerator = tf.reduce_sum(tf.multiply(0.5*tf.trace(tf.matmul(mse_weights,tf.matmul(UhH,tf.matmul(GVh_other_users,HhU)))),user_weights[:,:,0,0]), axis =1) \n","    sixth_term_numerator = tf.reduce_sum(tf.multiply(0.5*tf.trace(tf.matmul(mse_weights,tf.matmul(UhH,tf.matmul(VGh_other_users,HhU)))),user_weights[:,:,0,0]), axis =1) \n","\n","\n","    # SEVENTH TERM NUMERATOR\n","    trace_WUhU = 0.5*tf.trace(WUhU) \n","\n","    seventh_term_numerator = tf.reduce_sum(tf.multiply(tf.multiply(tf.tile(tf.expand_dims(-1*noise_power*(1/total_power)*tf.trace(GVh_all_users),axis = -1),(1,nr_of_users)),trace_WUhU)\\\n","                                                       ,user_weights[:,:,0,0]), axis =1) # B\n","    \n","    numerator = (first_term_numerator +  second_term_numerator - third_term_numerator - fourth_term_numerator + fifth_term_numerator + sixth_term_numerator - seventh_term_numerator)\n","\n","\n","    ############################################################################\n","    # DENOMINATOR\n","    ############################################################################\n","    \n","    # FIRST TERM DENOMINATOR\n","    GGh = tf.matmul(gradient,Gh) \n","    first_term_denominator =  tf.reduce_sum(tf.multiply(0.5*tf.trace(tf.matmul(mse_weights,tf.matmul(UhH,tf.matmul(GGh,HhU)))),user_weights[:,:,0,0]),axis = -1)\n","\n","\n","    # SECOND TERM DENOMINATOR\n","    GGh_all_users = tf.reduce_sum(GGh,axis = 1) \n","    GGh_other_users = tf.tile(tf.expand_dims(GGh_all_users,axis = 1),(1,nr_of_users,1,1)) - GGh \n","\n","    second_term_denominator = tf.reduce_sum(tf.multiply(0.5*tf.trace(tf.matmul(mse_weights,tf.matmul(UhH,tf.matmul(GGh_other_users,HhU)))),user_weights[:,:,0,0]),axis = -1)\n","\n","\n","    # THIRD TERM DENOMINATOR\n","    GGh_trace = tf.tile(tf.expand_dims(tf.reduce_sum(0.5*tf.trace(GGh),axis = 1),axis = -1),(1,nr_of_users)) \n","    third_term_denominator = noise_power*(1/total_power)*tf.reduce_sum(tf.multiply( tf.multiply(GGh_trace,trace_WUhU),user_weights[:,:,0,0]),axis = 1) \n","\n","    \n","    denominator = 2*(first_term_denominator + second_term_denominator + third_term_denominator) \n","\n","    step_size = tf.expand_dims(tf.expand_dims(tf.tile(tf.expand_dims((numerator/(denominator + epsilon_numerical_instability)),axis = -1),(1,nr_of_users)), axis = -1), axis = -1)\n","    updated_transmitter_precoder = V_a -step_size*step_size_factor*gradient \n","    \n","    return updated_transmitter_precoder, V, step_size_factor_temp, momentum1, momentum2\n","   \n","\n","# Builds one Nesterov-accelerated GD iteration of the U update in the unfolded matrix-inverse-free WMMSE and computes the optimal step size\n","def GD_step_U_line_search_more_streams_Nesterov( init, init_momentum1, init_momentum2, name, mse_weights, user_weights, U, U_past, H, V,VVh, noise_power):\n","\n","  with tf.variable_scope(name): \n","    \n","    epsilon_numerical_instability = 10**(-9)\n","    step_size_factor_temp =  tf.Variable(tf.constant(init, dtype=tf.float64), name=name, dtype=tf.float64)\n","    step_size_factor = 2*tf.math.sigmoid(step_size_factor_temp)\n","    momentum1 =  tf.Variable(tf.constant(init_momentum1, dtype = tf.float64), name = \"momentum_1\", dtype = tf.float64,trainable = True)\n","    momentum2 =  tf.Variable(tf.constant(init_momentum2, dtype = tf.float64), name = \"momentum_2\", dtype = tf.float64,trainable = True)\n","\n","    U_a = U + momentum1*(U - U_past)\n","    U_b = U + momentum2*(U - U_past)\n","\n","    first_term = -1*tf.matmul(H,V)\n","    second_term = tf.matmul(tf.matmul(tf.matmul(H, VVh), tf.transpose(H, perm = [0,1,3,2])), U_b)\n","\n","    power_V = tf.tile(tf.expand_dims(tf.tile(tf.expand_dims(tf.tile(tf.trace(VVh)*0.5,(1,nr_of_users)),axis = -1),(1,1,2*nr_of_UE_antennas)),axis = -1),(1,1,1,2*nr_of_data_streams)) \n","    third_term = noise_power*(1/total_power)*tf.multiply(U_b,power_V)\n","\n","    gradient = 2*tf.multiply(user_weights,tf.matmul((first_term + second_term + third_term), mse_weights)) \n","\n","    ######################################\n","    # FIND OPTIMAL STEP SIZE##############\n","    ######################################\n","\n","    #############################\n","    # NUMERATOR\n","    #############################\n","    power_V = tf.tile(tf.expand_dims(tf.tile(tf.expand_dims(tf.tile(tf.trace(VVh)*0.5,(1,nr_of_users)),axis = -1),(1,1,2*nr_of_data_streams)),axis = -1),(1,1,1,2*nr_of_data_streams)) \n","\n","    first_term_num = 0.5*tf.trace(tf.matmul(mse_weights,tf.matmul(tf.matmul(tf.matmul(tf.matmul(tf.transpose(U_a, perm = [0,1,3,2]),H),VVh),tf.transpose(H, perm = [0,1,3,2])), gradient)))\n","    second_term_num = 0.5*tf.trace(tf.matmul(mse_weights,tf.matmul(tf.matmul(tf.matmul(tf.matmul(tf.transpose(gradient, perm = [0,1,3,2]),H),VVh),tf.transpose(H, perm = [0,1,3,2])), U_a)))\n","\n","    third_term_num = 0.5*tf.trace(tf.matmul(mse_weights,noise_power*(1/total_power)*tf.multiply(tf.matmul(tf.transpose(U_a,perm = [0,1,3,2]),gradient),power_V)))\n","    fourth_term_num = 0.5*tf.trace(tf.matmul(mse_weights,noise_power*(1/total_power)*tf.multiply(tf.matmul(tf.transpose(gradient,perm = [0,1,3,2]),U_a),power_V)))\n","\n","    fifth_term_num = -1*0.5*tf.trace(tf.matmul(mse_weights,tf.matmul(tf.matmul(tf.transpose(V, perm = [0,1,3,2]), tf.transpose(H, perm = [0,1,3,2])), gradient)))\n","    sixth_term_num = -1*0.5*tf.trace(tf.matmul(mse_weights,tf.matmul(tf.matmul(tf.transpose(gradient, perm = [0,1,3,2]), H), V)))\n","\n","    numerator = first_term_num + second_term_num + third_term_num + fourth_term_num + fifth_term_num + sixth_term_num\n","\n","    #############################\n","    # DENOMINATOR\n","    ##############################\n","\n","    first_term_den = tf.trace(tf.matmul(mse_weights,noise_power*(1/total_power)*tf.multiply(tf.matmul(tf.transpose(gradient, perm = [0,1,3,2]), gradient),power_V)))\n","    second_term_den = tf.trace(tf.matmul(mse_weights,tf.matmul(tf.matmul(tf.matmul(tf.matmul(tf.transpose(gradient, perm = [0,1,3,2]), H), VVh), tf.transpose(H, perm = [0,1,3,2])), gradient)))\n","    denominator = first_term_den + second_term_den + epsilon_numerical_instability\n","\n","    step_size = tf.expand_dims(tf.expand_dims((numerator/denominator),axis = -1), axis = -1)\n","\n","    updated_receiver_precoder = U_a - step_size*step_size_factor*gradient\n","\n","  return updated_receiver_precoder, U, step_size_factor_temp, momentum1, momentum2"]},{"cell_type":"markdown","source":["# **Tensorflow computation graph to run the matrix-inverse-free WMMSE algorithm**"],"metadata":{"id":"76Me-dCrnJ4X"}},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":70793,"status":"ok","timestamp":1652816162614,"user":{"displayName":"Lissy Pellaco","userId":"16790785239086063280"},"user_tz":-120},"id":"x0ObC3ugMtKM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2b61d6a6-afad-42cb-86ef-06376974f220"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"]}],"source":["tf.reset_default_graph()\n","\n","channel_input = tf.placeholder(tf.float64, shape = None, name = 'channel_input')\n","initial_tp = tf.placeholder(tf.float64, shape = None, name = 'initial_transmitter_precoder') \n","initial_tp_past = tf.placeholder(tf.float64, shape = None, name = 'initial_transmitter_precoder_past') # needed for the acceleration scheme\n","\n","initial_rp = tf.placeholder(tf.float64, shape = None, name = 'initial_receiver_precoder') \n","initial_rp_past = tf.placeholder(tf.float64, shape = None, name = 'initial_receiver_precoder_past') # needed for the acceleration scheme\n","\n","initial_transmitter_precoder = initial_tp\n","initial_transmitter_precoder_past = initial_tp_past\n","initial_receiver_precoder = initial_rp\n","initial_receiver_precoder_past = initial_rp_past\n","\n","# Arrays that contain the initialization values of the step sizes for receiver precoder\n","step_size_factor1_init_U = [0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n","step_size_factor2_init_U = [0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n","\n","# Arrays that contain the initialization values of the step sizes for receiver precoder\n","momentum1_1_init_U = [0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n","momentum1_2_init_U = [0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n","\n","# Arrays that contain the initialization values of the step sizes for receiver precoder\n","momentum2_1_init_U = [0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n","momentum2_2_init_U = [0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n","\n","# Arrays that contain the initialization values of the step sizes for transmitter precoder\n","step_size_factor1_init_V = [0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n","step_size_factor2_init_V = [0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n","step_size_factor3_init_V = [0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n","step_size_factor4_init_V = [0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n","\n","momentum1_1_init_V = [0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n","momentum1_2_init_V = [0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n","momentum1_3_init_V = [0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n","momentum1_4_init_V = [0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n","\n","momentum2_1_init_V = [0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n","momentum2_2_init_V = [0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n","momentum2_3_init_V = [0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n","momentum2_4_init_V = [0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n","\n","profit = [] # stores the WSR obtained at each iteration\n","profit_alternative = [] # stores the WSR (computed through the mse weights) obtained at each iteration for the training\n","\n","user_weights = tf.ones((batch_size,nr_of_users),dtype=tf.float64)\n","user_weights_U_expanded = tf.tile(tf.expand_dims(tf.tile(tf.expand_dims(user_weights,-1),(1,1,2*nr_of_UE_antennas)),-1), (1,1,1,2*nr_of_data_streams)) \n","\n","user_weights_A_expanded = tf.tile(tf.expand_dims(tf.tile(tf.expand_dims(user_weights,-1),(1,1,2*nr_of_BS_antennas)),-1),(1,1,1,2*nr_of_BS_antennas))\n","user_weights_V_expanded = tf.tile(tf.expand_dims(tf.tile(tf.expand_dims(user_weights,-1),(1,1,2*nr_of_BS_antennas)),-1),(1,1,1,2*nr_of_data_streams))\n","\n","\n","####################################\n","# UPDATE OF MSE WEIGHTS\n","####################################\n","I = tf.eye(2*nr_of_data_streams, 2*nr_of_data_streams, batch_shape = [batch_size, nr_of_users],dtype=tf.dtypes.float64) \n","\n","#FIRST TERM OF E\n","I_UhHV = I - tf.matmul(tf.matmul(tf.transpose(initial_receiver_precoder,perm = [0,1,3,2]),channel_input), initial_transmitter_precoder)\n","first_term = tf.matmul(I_UhHV, tf.transpose(I_UhHV, perm = [0,1,3,2]))\n","\n","#SECOND TERM OF E\n","VVh_single_user = tf.matmul(initial_transmitter_precoder,tf.transpose(initial_transmitter_precoder, perm = [0,1,3,2]))\n","VVh = tf.expand_dims(tf.reduce_sum(VVh_single_user, axis = 1), axis = 1) \n","VVh_other_users = VVh - VVh_single_user\n","UhHVVhHhU = tf.matmul(tf.matmul(tf.matmul(tf.matmul(tf.transpose(initial_receiver_precoder, perm = [0,1,3,2]), channel_input),VVh_other_users), tf.transpose(channel_input, perm = [0,1,3,2])),initial_receiver_precoder)\n","second_term = UhHVVhHhU \n","\n","#THIRD TERM OF E \n","power_V = tf.tile(tf.expand_dims(tf.tile(tf.expand_dims(tf.tile(tf.trace(VVh)*0.5,(1,nr_of_users)),axis = -1),(1,1,2*nr_of_data_streams)),axis = -1),(1,1,1,2*nr_of_data_streams)) \n","third_term = noise_power *(1/total_power)* tf.multiply(tf.matmul(tf.transpose(initial_receiver_precoder, perm = [0,1,3,2]),initial_receiver_precoder),power_V)\n","\n","E = first_term + second_term + third_term \n","\n","###########################################\n","# SCHULZ WITH SPECTRAL RADIUS NORMALIZATION\n","###########################################\n","\n","mse_weights_init = tf.multiply(I,tf.tile(tf.expand_dims(tf.tile(tf.expand_dims(tf.reciprocal(0.5*tf.trace(E)),axis = -1),(1,1,2*nr_of_data_streams)),axis = -1),(1,1,1,2*nr_of_data_streams))) \n","\n","D = tf.matmul(E,mse_weights_init)\n","abs_D = tf.sqrt((D**2)[:,:,:nr_of_data_streams,:nr_of_data_streams] + (D**2)[:,:,:nr_of_data_streams,-nr_of_data_streams:] ) \n","sum_abs_D = tf.expand_dims(tf.reduce_sum(abs_D, axis = 2),axis = -1) \n","\n","g = tf.reduce_max(tf.matmul(abs_D,sum_abs_D),axis = [-2,-1]) \n","scaling = tf.sqrt(tf.tile(tf.expand_dims(tf.tile(tf.expand_dims(g,axis = -1),(1,1,2*nr_of_data_streams)),axis = -1),(1,1,1,2*nr_of_data_streams))) \n","                    \n","mse_weights_input = tf.divide(mse_weights_init,scaling)\n","\n","mse_weights1 = Schulz(mse_weights_input,E,I)\n","mse_weights = Schulz(mse_weights1,E,I)\n","\n","\n","for loop in range(0,nr_of_iterations_nn):\n","\n","  # To update VVh for receiver precoder\n","  VVh = tf.expand_dims(tf.reduce_sum(tf.matmul(initial_transmitter_precoder,tf.transpose(initial_transmitter_precoder, perm = [0,1,3,2])), axis = 1), axis = 1)\n","\n","  #######################################\n","  # UPDATE OF RECEIVER PRECODER \n","  #######################################\n","\n","  receiver_precoder1, receiver_precoder_past1, step_size1_U, momentum1_1_U, momentum2_1_U = GD_step_U_line_search_more_streams_Nesterov( step_size_factor1_init_U[loop], momentum1_1_init_U[loop], momentum2_1_init_U[loop],\"GD1\", mse_weights, user_weights_U_expanded, initial_receiver_precoder, initial_receiver_precoder_past, channel_input, initial_transmitter_precoder, VVh, noise_power) \n","  receiver_precoder_final, receiver_precoder_past2, step_size2_U , momentum1_2_U, momentum2_2_U = GD_step_U_line_search_more_streams_Nesterov( step_size_factor2_init_U[loop], momentum1_2_init_U[loop], momentum2_2_init_U[loop],\"GD2\", mse_weights, user_weights_U_expanded, receiver_precoder1, receiver_precoder_past1, channel_input, initial_transmitter_precoder,  VVh, noise_power) \n","\n","\n","  ####################################\n","  # UPDATE OF MSE WEIGHTS\n","  ####################################\n","\n","  #FIRST TERM OF E\n","  I_UhHV = I - tf.matmul(tf.matmul(tf.transpose(receiver_precoder_final,perm = [0,1,3,2]),channel_input), initial_transmitter_precoder)\n","  first_term = tf.matmul(I_UhHV, tf.transpose(I_UhHV, perm = [0,1,3,2]))\n","\n","  #SECOND TERM OF E\n","  VVh_single_user = tf.matmul(initial_transmitter_precoder,tf.transpose(initial_transmitter_precoder, perm = [0,1,3,2]))\n","  VVh = tf.expand_dims(tf.reduce_sum(VVh_single_user, axis = 1), axis = 1)\n","  VVh_other_users = VVh - VVh_single_user\n","  UhHVVhHhU = tf.matmul(tf.matmul(tf.matmul(tf.matmul(tf.transpose(receiver_precoder_final, perm = [0,1,3,2]), channel_input),VVh_other_users), tf.transpose(channel_input, perm = [0,1,3,2])),receiver_precoder_final)\n","  second_term = UhHVVhHhU \n","\n","  #THIRD TERM OF E\n","  power_V = tf.tile(tf.expand_dims(tf.tile(tf.expand_dims(tf.tile(tf.trace(VVh)*0.5,(1,nr_of_users)),axis = -1),(1,1,2*nr_of_data_streams)),axis = -1),(1,1,1,2*nr_of_data_streams))\n","  third_term = noise_power *(1/total_power)* tf.multiply(tf.matmul(tf.transpose(receiver_precoder_final, perm = [0,1,3,2]),receiver_precoder_final),power_V)\n","\n","  E = first_term + second_term + third_term\n","\n","\n","  ###########################################\n","  # SCHULZ WITH SPECTRAL RADIUS NORMALIZATION\n","  ###########################################\n","\n","  D = tf.matmul(E,mse_weights)\n","  abs_D = tf.sqrt((D**2)[:,:,:nr_of_data_streams,:nr_of_data_streams] + (D**2)[:,:,:nr_of_data_streams,-nr_of_data_streams:] ) \n","  sum_abs_D = tf.expand_dims(tf.reduce_sum(abs_D, axis = 2),axis = -1) \n"," \n","  g = tf.reduce_max(tf.matmul(abs_D,sum_abs_D),axis = [-2,-1]) \n","  scaling = tf.sqrt(tf.tile(tf.expand_dims(tf.tile(tf.expand_dims(g,axis = -1),(1,1,2*nr_of_data_streams)),axis = -1),(1,1,1,2*nr_of_data_streams))) \n","                      \n","  mse_weights_input = tf.divide(mse_weights,scaling)\n","\n","  mse_weights1 = Schulz(mse_weights_input,E,I)\n","  mse_weights = Schulz(mse_weights1,E,I)\n","\n","\n","  ##########################################\n","  # UPDATE OF TRANSMITTER PRECODER\n","  ##########################################\n","  \n","  A = tf.expand_dims(tf.reduce_sum(tf.multiply(user_weights_A_expanded, tf.matmul(tf.matmul(tf.matmul(tf.matmul(tf.transpose(channel_input, perm = [0,1,3,2]), receiver_precoder_final), mse_weights), tf.transpose(receiver_precoder_final, perm = [0,1,3,2])), channel_input)), axis = 1), axis = 1)\n","\n","  transmitter_precoder1, transmitter_precoder_past1, step_size1_V ,momentum1_1_V, momentum2_1_V= GD_step_V_line_search_more_streams_Nesterov( step_size_factor1_init_V[loop], momentum1_1_init_V[loop], momentum2_1_init_V[loop],\"step_size1_V\", mse_weights, user_weights_V_expanded, receiver_precoder_final, channel_input, initial_transmitter_precoder,initial_transmitter_precoder_past, A, total_power)\n","  transmitter_precoder2, transmitter_precoder_past2, step_size2_V ,momentum1_2_V, momentum2_2_V= GD_step_V_line_search_more_streams_Nesterov( step_size_factor2_init_V[loop], momentum1_2_init_V[loop], momentum2_2_init_V[loop],\"step_size2_V\", mse_weights, user_weights_V_expanded, receiver_precoder_final, channel_input, transmitter_precoder1,transmitter_precoder_past1, A, total_power)\n","  transmitter_precoder3, transmitter_precoder_past3, step_size3_V ,momentum1_3_V, momentum2_3_V= GD_step_V_line_search_more_streams_Nesterov( step_size_factor3_init_V[loop], momentum1_3_init_V[loop], momentum2_3_init_V[loop],\"step_size3_V\", mse_weights, user_weights_V_expanded, receiver_precoder_final, channel_input, transmitter_precoder2, transmitter_precoder_past2,A, total_power)\n","  transmitter_precoder_final, transmitter_precoder_past4, step_size4_V ,momentum1_4_V, momentum2_4_V= GD_step_V_line_search_more_streams_Nesterov( step_size_factor4_init_V[loop], momentum1_4_init_V[loop], momentum2_4_init_V[loop],\"step_size4_V\", mse_weights, user_weights_V_expanded, receiver_precoder_final, channel_input, transmitter_precoder3, transmitter_precoder_past3,A, total_power)\n","\n","\n","  ##############################################################################\n","  # For the next loop\n","  initial_transmitter_precoder = transmitter_precoder_final\n","  initial_receiver_precoder = receiver_precoder_final\n","  ##############################################################################  \n","\n","  ##############################################################################\n","  if scale_V_every_iteration == True:\n","      transmitter_precoder_power = tf.expand_dims(tf.reduce_sum((0.5*(tf.norm(transmitter_precoder_final, axis=[-2,-1] ))**2),axis = 1),axis = -1) \n","      power_scaling_ref = tf.divide(1, tf.sqrt(transmitter_precoder_power))*tf.sqrt(tf.cast(total_power,dtype = tf.float64)) \n","      power_scaling_expanded = tf.tile(tf.expand_dims(tf.tile(tf.expand_dims(tf.tile(power_scaling_ref,(1,nr_of_users)),axis = -1),(1,1,2*nr_of_BS_antennas)),axis = -1),(1,1,1,2*nr_of_data_streams))\n","      initial_transmitter_precoder = tf.multiply(transmitter_precoder_final, power_scaling_expanded)\n","  ##############################################################################\n","\n","  # LOSS FUNCTION\n","  # scale the transmit precoder at the last iteration\n","  if  loop == (nr_of_iterations_nn-1.0) and scale_V_every_iteration == False :\n","    transmitter_precoder_power = tf.expand_dims(tf.reduce_sum((0.5*(tf.norm(transmitter_precoder_final, axis=[-2,-1] ))**2),axis = 1),axis = -1) \n","    power_scaling_ref = tf.divide(1, tf.sqrt(transmitter_precoder_power))*tf.sqrt(tf.cast(total_power,dtype = tf.float64)) \n","    power_scaling_expanded = tf.tile(tf.expand_dims(tf.tile(tf.expand_dims(tf.tile(power_scaling_ref,(1,nr_of_users)),axis = -1),(1,1,2*nr_of_BS_antennas)),axis = -1),(1,1,1,2*nr_of_data_streams))\n","    initial_transmitter_precoder = tf.multiply(transmitter_precoder_final, power_scaling_expanded)\n","  \n","  profit.append(compute_WSR_neural_network(channel_input, initial_transmitter_precoder, noise_power,user_weights, batch_size))\n","\n","\n","  if loop == (nr_of_iterations_nn-2.0):\n","\n","      # we scale the final precoder to meet the power constraint\n","      if scale_V_every_iteration == False:\n","        transmitter_precoder_power = tf.expand_dims(tf.reduce_sum((0.5*(tf.norm(transmitter_precoder_final, axis=[-2,-1] ))**2),axis = 1),axis = -1)\n","        power_scaling_ref = tf.divide(1, tf.sqrt(transmitter_precoder_power))*tf.sqrt(tf.cast(total_power,dtype = tf.float64))\n","        power_scaling_expanded = tf.tile(tf.expand_dims(tf.tile(tf.expand_dims(tf.tile(power_scaling_ref,(1,nr_of_users)),axis = -1),(1,1,2*nr_of_BS_antennas)),axis = -1),(1,1,1,2*nr_of_data_streams))                     \n","        initial_transmitter_precoder = tf.multiply(transmitter_precoder_final, power_scaling_expanded)\n","\n","      # compute the WSR given by transmitter_precoder_to_use\n","      WSR_from_V_previous_iteration = compute_WSR_neural_network(channel_input, initial_transmitter_precoder, noise_power,user_weights, batch_size)\n","\n","WSR = tf.reduce_sum(profit)\n","WSR_final = profit[-1]\n","\n","optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(-WSR)\n"]},{"cell_type":"markdown","source":["# **Running the unfolded matrix-inverse-free WMMSE and the WMMSE**\n","In this code, we train the unfolded matrix-inverse-free WMMSE network and we compare its performance with the WMMSE by testing both approaches on the same dataset of channel realizations."],"metadata":{"id":"hxzVE8-nmKvj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"v7VCO3y7Mu9S"},"outputs":[],"source":["WSR_WMMSE =[] # to store the WSR attained by the WMMSE\n","WSR_ZF = [] # to store the WSR attained by the zero-forcing \n","WSR_RZF = [] # to store the WSR attained by the regularized zero-forcing\n","WSR_nn = [] # to store the WSR attained by the deep unfolded WMMSE\n","training_loss = []\n","WSR_from_W = []\n","\n","initial_transmitter_precoder_batch_past = np.zeros((nr_of_samples_per_batch,nr_of_users,nr_of_BS_antennas*2,2*nr_of_data_streams)) # for the acceleration scheme\n","initial_receiver_precoder_batch_past = np.zeros((nr_of_samples_per_batch,nr_of_users,nr_of_UE_antennas*2,2*nr_of_data_streams)) # for the acceleration scheme\n","\n","with tf.Session() as sess:\n","\n","    np.random.seed(5678) ##REMOVEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n","    print(\"start of session\")\n","    start_of_time = time.time()\n","    sess.run(tf.global_variables_initializer())\n","   \n","    for i in range(nr_of_batches_training):\n","      batch_for_training = []\n","      initial_transmitter_precoder_batch = []\n","      initial_receiver_precoder_batch = []\n","            \n","      # Building a batch for training\n","      for ii in range(nr_of_samples_per_batch):\n","        channel_realization_nn, init_transmitter_precoder, init_receiver_precoder, _,_ = compute_channel(nr_of_BS_antennas, nr_of_users, total_power)\n","        batch_for_training.append(channel_realization_nn)\n","        initial_transmitter_precoder_batch.append(init_transmitter_precoder)\n","        initial_receiver_precoder_batch.append(init_receiver_precoder)\n","     \n","      # Training\n","      sess.run(optimizer, feed_dict={channel_input:batch_for_training,initial_tp:initial_transmitter_precoder_batch , initial_tp_past:initial_transmitter_precoder_batch_past, initial_rp:initial_receiver_precoder_batch, initial_rp_past:initial_receiver_precoder_batch_past })\n","      training_loss.append(-1*(sess.run(WSR, feed_dict={channel_input:batch_for_training,initial_tp:initial_transmitter_precoder_batch , initial_tp_past:initial_transmitter_precoder_batch_past, initial_rp:initial_receiver_precoder_batch, initial_rp_past:initial_receiver_precoder_batch_past})))\n","\n","    # For repeatability\n","    np.random.seed(1234)\n","\n","    WSR_WMMSE_batch = 0.0\n","    \n","    for i in range(nr_of_batches_test):    \n","      batch_for_testing = []\n","      initial_transmitter_precoder_batch = []\n","      initial_receiver_precoder_batch = []\n","   \n","      # Building a batch for testing\n","      for ii in range(nr_of_samples_per_batch):       \n","        channel_realization_nn, init_transmitter_precoder,init_receiver_precoder, channel_WMMSE, initial_transmitter_precoder_WMMSE = compute_channel(nr_of_BS_antennas, nr_of_users, total_power)          \n","\n","        batch_for_testing.append(channel_realization_nn)\n","        initial_transmitter_precoder_batch.append(init_transmitter_precoder)\n","        initial_receiver_precoder_batch.append(init_receiver_precoder)\n","\n","        _,_,_, WSR_WMMSE_one_sample = run_WMMSE_MIMO_more_streams(epsilon, channel_WMMSE, initial_transmitter_precoder_WMMSE, total_power, noise_power, user_weights_WMMSE, nr_of_iterations_WMMSE, log = False)\n","        WSR_WMMSE_batch =  WSR_WMMSE_batch + WSR_WMMSE_one_sample\n","\n","      #Testing\n","      WSR_nn.append(sess.run(WSR_final , feed_dict={channel_input:batch_for_testing,initial_tp:initial_transmitter_precoder_batch , initial_tp_past:initial_transmitter_precoder_batch_past, initial_rp:initial_receiver_precoder_batch, initial_rp_past:initial_receiver_precoder_batch_past }))\n","\n","print(\"The WSR achieved with unfolded matrix-inverse-free WMMSE is: \", np.mean(WSR_nn))\n","print(\"The WSR achieved with the WMMSE algorithm is: \", WSR_WMMSE_batch/(nr_of_samples_per_batch*nr_of_batches_test))\n","\n","plt.figure()\n","plt.plot(training_loss)\n","plt.ylabel(\"Training loss\")\n","plt.xlabel(\"Sample index\")\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"For_upload.ipynb","provenance":[{"file_id":"1tu-CW2J7U5HwhTlxMw1cY2cO4FCFHrNt","timestamp":1651697122240},{"file_id":"1pNLNrFdZGLKPKK-ol9R_8Bzz-o4Fj8HM","timestamp":1643372524609},{"file_id":"1umZkKYwAUnr6esB3LFPPI8OUHv7N-9gR","timestamp":1638135711153},{"file_id":"1O86702cT4NfullOCAdu52NSkRTkkLuYf","timestamp":1635022300466},{"file_id":"1FSv6DTHtwoCb-sKwmSffPKlbQq-O7viM","timestamp":1634933406294},{"file_id":"1I6sELyOt07u2VmpNEFGNt9dp0bLMMii7","timestamp":1634765569037},{"file_id":"1UGLLOZb1g3CPQA-6kazJT2lVM8bPnFKv","timestamp":1629557323075},{"file_id":"1hk5MK2YraIyQyHfA_ldr6EyAwlcq-yJh","timestamp":1629318469387},{"file_id":"1ZFXHuA8Wh6L6Pd7EXoKti7Cnm1G5mXN_","timestamp":1625157469313},{"file_id":"1wNeYxdwMwUmwHgoNo0uIZk1EWJCXXGlf","timestamp":1624872317998},{"file_id":"1SJvYau2GgAiYh-NshzNAdLvF65y1I5UG","timestamp":1624667991584}],"authorship_tag":"ABX9TyOpvdae+FeZTKjo40nUmSNv"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}